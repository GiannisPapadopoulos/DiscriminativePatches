% $Id

%% Dokumentenklasse (Koma Script) -----------------------------------------
\documentclass[%
   %draft,     % Entwurfsstadium
   final,      % fertiges Dokument
	 % --- Paper Settings ---
   paper=a4,% [Todo: add alternatives]
   paper=portrait, % landscape
   pagesize=auto, % driver
   % --- Base Font Size ---
   fontsize=10pt,%
	 % --- Koma Script Version ---
   version=last, %
 ]{scrartcl} % Classes: scrartcl, scrreprt, scrbook


% Encoding der Dateien (sonst funktionieren Umlaute nicht)
% Fuer Linux -> utf8
% Fuer Windows, alte Linux Distributionen -> latin1

% Empfohlen latin1, da einige Pakete mit utf8 Zeichen nicht
% funktionieren, z.B: listings, soul.

%\usepackage[latin1]{inputenc}
%\usepackage[ansinew]{inputenc}
\usepackage[utf8]{inputenc}
%\usepackage{ucs}
%\usepackage[utf8x]{inputenc}

\usepackage[T1]{fontenc}
\usepackage[english]{babel}
 
%\usepackage[
%backend=biber,
%style=alphabetic,
%citestyle=authoryear 
%]{biblatex}
 

%\usepackage[babel]{ngerman}
%\usepackage[american]{babel}
%\usepackage{csquotes}
%\usepackage[style=authoryear]{biblatex} 
%\usepackage[style=apa]{biblatex}
%\DeclareLanguageMapping{american}{american-apa}
%\DeclareLanguageMapping{german}{german-apa}

%\addbibresource{maip4.bib} %Imports bibliography file

%\usepackage{mathptmx}
%\usepackage[scaled]{uarial}

%\usepackage{subfigure}

\renewcommand{\rmdefault}{phv} % Arial
\renewcommand{\sfdefault}{phv} % Arial

\usepackage{listings}
\usepackage{color}
\usepackage{graphicx}
\usepackage{caption}

\usepackage{geometry,array,graphicx,float,caption}
\usepackage{subcaption}

\usepackage{float}
%\usepackage{tikz}
%\usetikzlibrary{arrows}


\sffamily

%% Titel -----------------------------------------
\title{Research Project Master Artifical Intelligence Group 4}
\subtitle{Mid-level Discriminative Patches}
\author{Stefan Selzer I6123079}


%% Dokument -----------------------------------------
\begin{document}

\maketitle

\newpage
\tableofcontents
\newpage
\section{Introduction}\label{sec:Introduction}
Unsupervised Discovery of mid-level discriminative patches is a method to extract from an image the primitives for visual information that satisfy the requirements of being representative as well as discriminative and that have been discovered in a fully unsupervised manner. The method was elaborated by Singh et Al. at the Carnegie Mellon University of Pittsburgh, Pennsylvania, and published at the European Conference on Computer Vision in the year 2012.\cite[Singh2012]{Singh2012DiscPat} The method is settled in the fields of computer vision and machine learning and combines techniques from these fields to produce promising results in image recognition and classification. Singh et Al. showed the capabilities of their method in a follow-up publication “What Makes Paris Look like Paris?”.\cite[Doersch2012]{doersch2012what} Here they identified the most distinct elements on images of architecturally different cities like Paris and London classifying these images as being shot in the corresponding city.
\\
\\
The idea of this project is to apply this method on the classification of images of human facial expressions. This could for example aid in human computer interaction to recognize particular emotions or cognitive states through visual or expressive features contained in an image.
\\
Put in one phrase the goal of this project is to find classifiers for human facial expressions.
In detail the requirements are to deliver an extensible, easy-to –use and well documented code base using C++ as programming language and the image processing library OpenCV as toolset for the basic techniques and algorithms needed to implement the functionality.
\\
\\
This paper describes the results of the research project by first giving an overview of the technical background and describing the method implemented by Singh et Al.. Then the project work is presented and finally and outlook on possible future work is given.





\section{Technological Background}\label{sec:StateArt}

This chapter gives an explanation of definitions used and an overview of the algorithm proposed by Singh et Al. as well as the image processing techniques used therein.

\subsection{Image Patches}

To explain the notion of mid-level discriminative patches it is best to first take a look at the different levels of visual information that can be retrieved from an image. Approaching from bottom-up, the lowest level would correspond to a single pixel. But single pixels do obviously not provide much useful information to describe features of the real world. From top-down, the highest level would be the image as a whole. This imposes several problems such as a high number of spatial configurations needed to describe objects as well as too much unnecessary information to describe certain features contained in that image. The best way is found in between by looking at parts of the image that are just right to describe a certain feature of an image. Such parts are called mid-level image patches.
\\
\\
Singh et Al. define such patches as being discriminative if they are representative concerning the described feature and different enough from other patches describing the same or any other feature. Additionally they require such patches to be detectable with “high recall and precision” in a large number of images.\cite[Singh2012]{Singh2012DiscPat}

\subsection{Applied Techniques}

The algorithm to detect discriminative patches in an unsupervised manner mainly consists of three parts:
\\
The first one is to extract features from an image, then these features are clustered and the clusters are train a linear support vector machine (SVM) used to classify new elements in the end.
\\
\\
The feature extraction is supposed to be done using histogram of oriented gradients (HOG). The features are computed as intensity gradients for small parts of an image. The edge directions defined like this are then counted and concatenated to form a comprehensive descriptor. One of the key advantages of this technique is that it is invariant to geometric or photometric transformations.\cite[Dalal2005]{Dalal:2005:HOG:1068507.1069007}
\\
\\
Clustering is done using k-means clustering. K-means clustering partitions a dataset into a given number of clusters in such a way that the sum of the quadratic deviations from each cluster centroid is minimized. As metric usually the Euclidian distance is used.\cite[Coates2012]{DBLP:series/lncs/CoatesN12}
\\
\\
A linear SVM separates points with a hyperplane that has a maximized distance to the nearest data points on each side of the plane. This can be used as binary classifier to classify input data according to recognized patterns. These patterns are obtained by training the SVM on positive and negative samples of data describing the problem that needs to be solved by classification.\cite[Chang2011]{Chang:2011:LLS:1961189.1961199}

\subsection{Proposed Algorithm}

Applying these techniques, the feature extraction using HOG descriptors produces a large number of possibly overlapping patches at multiple scales. If one would now know that some of these patches are similar, these could be used to train a SVM for classification. Fortunately a similarity can also be produced by clustering the patches using k-means clustering. The problem with the low-level metric used by k-means clustering is that it does not produce good results on image patches. To address this again a SVM could be trained to produce a similarity metric needed to refine these clusters. So the clustering depends on the similarity metric of the SVM while the SVM itself depends on the clusters to be trained. To solve this problem the described approach is done in an iterative way. First the data is clustered in HOG space then a SVM is trained using the clusters to produce a metric which then is used to refine the clusters. This is done until a convergence criterion is reached. The final classifiers then are ranked according to their purity and discriminativeness.
\\
Purity is defined as the sum of the classifiers detection scores of the top cluster members.
\\
Discriminativeness describes the ratio of detections on the positive training data and the union of the positive and negative training data. This ratio should be low but still above 0.
\\
\\
The drawback of the described process is that classifier might suffer from overfitting. Overfitting occurs for example when the number of features exceeds the number of training datasets. The effect then is that the classifier does not predict by generalizing from what he has learned but memorizes input patterns and recalls them. It can be measured when the prediction of training samples is far more accurate than the prediction of unknown validation data. To prevent this overfitting Singh et Al. divided the input data of the algorithm consisting of positive examples containing the features that are searched and negative ones not containing this feature further into two datasets each. From these two positive and negative training datasets one will then act as training and the other one as validation dataset. In each iteration of the algorithm, the datasets are flipped for the next iteration to enhance the clusters by new feature patches. Furthermore, the best patches recognized in the validation dataset will be added to the training data patches to ensure even more diversity.\cite[Singh2012]{Singh2012DiscPat}


\section{Project work}\label{sec:projectwork}
This chapter presents the group’s work conducted so far. First the project setup and preliminary work is described then the implementation of the algorithm is explained.

\subsection{Project setup}

To enable collaborative work in a software development project basic standards have to be clarified. This includes an agreement on which techniques to use and according to what standards code will be written as well as to define mandatory versions of underlying toolsets and frameworks.
\\
\\
Most important is to answer the question how to exchange the code and any other material between the participating group members. The UM Blackboard for example provides file exchange mechanisms that will mainly be used to exchange official data like protocols especially when access from the project supervisors is obliged. It will also be used to exchange large binary data like image datasets needed for the experiments.
\\
\\
To share the code and any textual data produced in the course of this project a code repository is used. The choice was made to setup a project on GitHub because it is easy and uncomplicated to access and to work with.
\\
\\
The programming language was presumed to be C++ in the projects description. The framework was suggested to be OpenCV which is an Open Source image processing toolkit for C++ providing state of the art image processing algorithm and tools. Version 2.4 was agreed on to be used for the implementation of the project’s work.
\\
\\
The project's codebase is configured using CMake. CMake is a platform independent build tool for C++ that enables a simple setup of abstract and generic compiler related configurations from which concrete build information like Makefiles used by the GNU compiler chain on Linux or Visual Studio project files for Microsoft Windows can be generated automatically thus eliminating the need to maintain multiple version of such definitions for multiple and heterogeneous development environments like they are given on the laptops and computers of the project members.
\\
\\
The need to produce extensible and well documented code will be fulfilled by providing a comprehensive report as well as inline code documentation. For the latter Doxygen is considered to be the best choice. Thereby a complete and always up to date code description on html pages can be generated automatically from the comments that should be added to the code anyway.
\\
\\
Armed with these tools the application described in the following section is being developed.

\subsection{Software Application}

The application is capable of loading image datasets from two folders defined on the command-line input. One of them has to be the dataset containing the positive features and the other one the dataset containing any other features except those from the positive dataset. The application splits the datasets into defined parts for training and validation. To obtain more data needed for successful training, additional images from the horizontally flipped versions of the input images are computed and added to the datasets. Then the features for all images are computed using the OpenCV HOGDescriptor. To enhance the feature detection the images are adjusted beforehand by histogram equalization using the corresponding OpenCV method to increase the contrast of the image and produce sharper edges for the edge gradient computation of the HOG feature extractor. The computed features for the positive and negative training datasets are then combined in a training matrix which his fed into the OpenCV SVM instance together with according labels indicating positive and negative samples in the training matrix. Finally the SVM predicts the patches from the validation datasets and the prediction results are displayed.
\\
\\
The application was used in the following experimental setup.

\section{Conducted Experiments}

The dataset used in the experiments is the Cohn-Kanade Database for facial expressions.\cite[Kanade2000]{Kanade2000CK+}\cite[Lucey2010]{Lucey2010CK+} As the application does not yet provide mechanism for clustering data, patches were extracted manually simulating optimal clusters of positive patches and clusters of corresponding negative features. Because it is the most distinguishable expression contained in the dataset, surprise was chosen as positive feature and the mouth was identified to be the promising most discriminative image patch. The amount of positive images thereby is 88 and for the negative images the same amount is chosen from about 400 images overall.
\\
\\
The test runs were conducted using different configurations, one using the average original patch size of 96x96 pixels divided by 4 cells of 48x48 each in the HOGDescriptor. The other one was based on a cell size of 8x8 pixels leading to rescaled patches of 16x16 pixels again using 4 cells per patch. The cell size had to be reduced to 4 because multiplied with the 9 bins indicating the gradient directions computed by the HOGDescriptor this gives a total of 36 features per patch. As the feature space should be by far smaller than the number of samples this still gives a relation of roughly one to four features to samples taken the doubled images from the flipping into account. Single cells would correspond to single features which are not expressive anymore and thereby not feasible.
\\
\\
Running the application on the extracted patches unfortunately did not yield good results. The predictions on the negative validation dataset were negative as they were expected. But also the prediction on the positive dataset was negative for all patches. A possible reason for this outcome is that the feature space is too high compared to the number of samples and thereby the effect of overfitting can be seen here.

\section{Conclusion and Future Work}

The paper described the work and results of the research project on Mid-level Discriminative Patches. An application has been developed making use of the main parts of the algorithm proposed by Singh et Al. namely the feature extraction using HOG and the trained classifier using SVM.
\\
\\
The results were not as good as expected which might be due to possible overfitting on the tested dataset. To fight this issue and enhance the work more data should be found and used in an additional test run.


%\bibliographystyle{apacite}
\bibliographystyle{plain}
\bibliography{maip4}

%\printbibliography

\end{document}
