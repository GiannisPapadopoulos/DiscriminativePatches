
\section{Technological Background}\label{sec:StateArt}

TODO: Overview of the paper and underlying techniques, state of the art
\\
\\
This section gives an explanation of definitions used and an overview of the algorithm proposed by Singh et Al. \cite{Singh2012DiscPat}. and the image processing techniques used therein.

\subsection{Image Patches}

To explain the notion of mid-level discriminative patches, it is best to first observe the different levels of visual information that can be retrieved from an image. From a bottom-up point-of-view, the lowest level corresponds to a single pixel, but single pixels do obviously not provide much useful information to describe features of the real world. On the opposite side, the highest level corresponds to the image as a whole. This poses several problems on the analysis of the retrieved information such as a high number of spatial configurations needed to describe objects. Also the image as a whole contains too much unnecessary information to describe certain features on their own. As Sing et Al. pointed out \cite{Singh2012DiscPat}, the optimal level of information is found by looking at medium-sized parts of the image that describe one certain feature of an image. Such parts are called mid-level image patches. Singh et Al. \cite{Singh2012DiscPat} define such patches as being discriminative if they clearly represent the described feature and if they are different enough from other patches describing the same or any other feature. Additionally, they require such patches to be detectable with "`high recall and precision"' in a large number of images.

\subsection{Proposed Algorithm}

The algorithm to detect discriminative patches in an unsupervised manner mainly consists of three parts: The first one is to extract features from an image, then these features are clustered and the clusters train a linear support vector machine (SVM) finally used to classify unknown images. The feature extraction is performed by using the Histogram of Oriented Gradients (HOG) presented by Dalal and Triggs \cite{Dalal:2005:HOG:1068507.1069007}. The features are computed as intensity gradients for small parts of an image. The computed edge directions are then counted and concatenated to form a comprehensive descriptor. One of the key advantages of this technique is that it is invariant to geometric or photometric transformations. Clustering is performed by using k-means clustering. This promising starting point for image classification has been presented by Coates et Al. \cite{DBLP:series/lncs/CoatesN12}. Basically, K-means clustering partitions a dataset into a given number of clusters in such a way that the sum of the quadratic deviations from each cluster centroid is minimized. As metric usually the Euclidian distance is used. A linear SVM separates points with a hyperplane that has a maximized distance to the nearest data points on each side of the plane. This can be used as binary classifier to classify input data according to recognized patterns as shown by Chang et Al. \cite{Chang:2011:LLS:1961189.1961199}. These patterns are obtained by training the SVM on positive and negative samples of data describing the problem that needs to be solved by classification.
\\
\\
Applying these techniques, the feature extraction using HOG descriptors produces a large number of possibly overlapping patches at multiple scales. If some of these patches are known to be similar, these similar patches could be used to train a SVM for classification. Fortunately, a similarity can be produced by clustering the patches using k-means clustering. The problem with the low-level metric used by k-means clustering is that it produces poor results on image patches. To refine the clusters, again, a SVM could be trained to produce a similarity metric. That means, that the clustering depends on the similarity metric of the SVM while the SVM itself depends on the clusters to be trained. To solve this problem the approach described approach is performed in an iterative way. First, the data is clustered in HOG space and then a SVM is trained. The SVM uses the clusters to produce a metric which then is used to refine the clusters. This is repeated until a convergence criterion is reached. The final classifiers are then ranked according to their purity and discriminativeness. Singh et Al. define purity as the sum of the classifiers detection scores of the top cluster members \cite{Singh2012DiscPat}. Discriminativeness describes the ratio of detections on the positive training data and the union of the positive and negative training data. This ratio should be low but still above 0.

\subsection{Problem of Overfitting}

The drawback of the process described is that the classifier might suffer from overfitting. Overfitting occurs, for example, when the number of features exceeds the number of training datasets. In this case, the classifier does not predict by generalizing from what he has learned but memorizes input patterns and recalls them. This effect can be measured by comparing the accuracy of the prediction of training data with the one of unknown validation data. In this case the prediction of training samples is far more accurate than the prediction of unknown validation data. To prevent this overfitting, Singh et Al. \cite{Singh2012DiscPat} divide the input data of the algorithm further into two datasets. One of these datasets consists of positive examples containing the features that are searched and the other one of negative examples not containing this particular feature. From these two datasets one will then act as a training and the other as a validation dataset. In each iteration of the algorithm, the datasets are exchanged for the next iteration to enhance the clusters by new feature patches. Furthermore, the patches in the the validation dataset, that are classified with the best score, will be added to the training data patches to ensure even more diversity.

