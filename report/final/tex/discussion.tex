\section{Discussion}
For the manually extracted patches the best overall results were obtained for the mouth region, with over 80\% of the images classified correctly.
This confirms our intuition as this region is the most distinguishable
from a human perspective. Results for the eye regions were better than expected, as visually the extracted patches look very similar. For the disgust emotion all
four regions lead to comparable results, while for the anger emotion the region between the eyes is almost as discriminative as the mouth.
Rescaling the images does not appear to have a very significant effect.
\\
\\
Performing SVM classification on the entire facial region led to good results if the region was rescaled to 96x96 pixels, better than all manually extracted
patches except the mouth. In this case there is a clear loss
of precision if the image is rescaled to 32x32 pixels.
\\
\\
Table \ref{table:predict_mouth} shows the result of prediction of mouth patches. Most parts of mouth patches were given correct classifications. However, for angry, fear, happy and surprise emotion, there are one or two ambiguous facial expressions so that the patches of them were classified to an incorrect emotion. By contrast, the prediction of right-eye patches was not as good as that of mouth patches. As Table\ref{table:predict_righteye} shows, right-eye patches of angry and fear emotions were not predicted correctly. For other emotions, the accuracy of the prediction of right-eye patches was lower than that of mouth patches.% TODO Run the experiment without face detection to measure the effect, discuss the original paper
\\
\\


